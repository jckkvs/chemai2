"""
frontend_streamlit/pages/automl_page.py

AutoML å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œãƒšãƒ¼ã‚¸ã€‚
EDA â†’ å‰å‡¦ç† â†’ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ â†’ è©•ä¾¡ â†’ æ¬¡å…ƒå‰Šæ¸› â†’ SHAPè§£æã¾ã§
ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§å®Ÿè¡Œã™ã‚‹ã€‚
"""
from __future__ import annotations

import time
import traceback
from dataclasses import dataclass, field
from typing import Any

import numpy as np
import pandas as pd
import plotly.graph_objects as go
from sklearn.pipeline import Pipeline
import streamlit as st

from backend.models.automl import AutoMLEngine, AutoMLResult
from backend.data.preprocessor import PreprocessConfig
from backend.data.type_detector import TypeDetector
from backend.data.eda import summarize_dataframe, compute_column_stats, detect_outliers
from backend.data.dim_reduction import run_pca
from backend.data.benchmark import evaluate_regression, evaluate_classification


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹: ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµæœ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class PipelineResult:
    """ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œçµæœã‚’ä¿æŒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã€‚"""
    eda_summary: dict[str, Any] = field(default_factory=dict)
    col_stats: list = field(default_factory=list)
    outlier_results: list = field(default_factory=list)
    automl_result: AutoMLResult | None = None
    model_score: Any | None = None          # ModelScore (å›å¸°/åˆ†é¡)
    pca_df: pd.DataFrame | None = None
    pca_evr: np.ndarray | None = None
    shap_importances: dict[str, float] = field(default_factory=dict)
    task: str = "regression"
    elapsed: float = 0.0
    warnings: list[str] = field(default_factory=list)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³ render é–¢æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def render(run_config: dict | None = None) -> None:
    st.markdown("## ğŸ¤– è§£æçµæœ")

    df = st.session_state.get("df")
    target_col = st.session_state.get("target_col")

    if df is None:
        st.warning("âš ï¸ ã¾ãšãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        if st.button("ğŸ  ãƒ›ãƒ¼ãƒ ã¸", key="goto_home_a"):
            st.session_state["page"] = "home"
            st.rerun()
        return

    if not target_col:
        st.warning("âš ï¸ ç›®çš„å¤‰æ•°ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ›ãƒ¼ãƒ ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        if st.button("ğŸ  ãƒ›ãƒ¼ãƒ ã¸", key="goto_home_b"):
            st.session_state["page"] = "home"
            st.rerun()
        return

    # â”€â”€ ãƒ›ãƒ¼ãƒ ã‹ã‚‰æ¸¡ã•ã‚ŒãŸè¨­å®šã§å³å®Ÿè¡Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if run_config is not None:
        _run_full_pipeline(
            df          = df,
            target_col  = run_config["target_col"],
            smiles_col  = run_config.get("smiles_col"),
            numeric_scaler = run_config.get("scaler", "auto"),
            task_override  = run_config.get("task", "auto"),
            cv_folds    = run_config.get("cv_folds", 5),
            max_models  = run_config.get("max_models", 8),
            timeout     = run_config.get("timeout", 300),
            do_eda      = run_config.get("do_eda", True),
            do_prep     = run_config.get("do_prep", True),
            do_ml       = True,
            do_eval     = run_config.get("do_eval", True),
            do_pca      = run_config.get("do_pca", True),
            do_shap     = run_config.get("do_shap", True),
        )
        return

    # â”€â”€ ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ãƒãƒ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    c1, c2, c3, c4 = st.columns(4)
    metric_items = [
        (c1, str(df.shape[0]), "ã‚µãƒ³ãƒ—ãƒ«æ•°"),
        (c2, str(df.shape[1] - 1), "ç‰¹å¾´é‡æ•°"),
        (c3, target_col, "ç›®çš„å¤‰æ•°"),
        (c4, str(df.select_dtypes(include="number").shape[1]), "æ•°å€¤åˆ—æ•°"),
    ]
    for col, val, lbl in metric_items:
        with col:
            st.markdown(
                f'<div class="metric-card"><div class="metric-value" style="font-size:1.2rem;">'
                f'{val}</div><div class="metric-label">{lbl}</div></div>',
                unsafe_allow_html=True,
            )

    st.markdown("---")

    # â”€â”€ Pipelineè¨­å®šãƒ‘ãƒãƒ«ï¼ˆæŠ˜ã‚Šç•³ã¿ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.expander("âš™ï¸ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°è¨­å®š", expanded=False):
        col_a, col_b, col_c = st.columns(3)
        with col_a:
            st.markdown("**MLè¨­å®š**")
            cv_folds   = st.slider("CVåˆ†å‰²æ•°", 2, 10, 5, key="pl_cv")
            max_models = st.slider("è©¦ã™ãƒ¢ãƒ‡ãƒ«æ•°", 1, 15, 8, key="pl_max")
            timeout    = st.slider("ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ(ç§’)", 30, 3600, 300, key="pl_to")
        with col_b:
            st.markdown("**å‰å‡¦ç†è¨­å®š**")
            numeric_scaler  = st.selectbox("æ•°å€¤ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼",
                ["auto", "standard", "robust", "minmax", "none"], key="pl_scaler")
            task_override   = st.selectbox("ã‚¿ã‚¹ã‚¯",
                ["auto", "regression", "classification"], key="pl_task")
            smiles_col_raw  = st.selectbox("SMILESåˆ—",
                ["ãªã—"] + df.columns.tolist(), key="pl_smiles")
            smiles_col = None if smiles_col_raw == "ãªã—" else smiles_col_raw
        with col_c:
            st.markdown("**å®Ÿè¡Œã™ã‚‹ãƒ•ã‚§ãƒ¼ã‚º**")
            do_eda   = st.checkbox("Phase 1: EDA",         value=True, key="pl_eda")
            do_prep  = st.checkbox("Phase 2: å‰å‡¦ç†ç¢ºèª",  value=True, key="pl_prep")
            do_ml    = st.checkbox("Phase 3: AutoML",       value=True, key="pl_ml")
            do_eval  = st.checkbox("Phase 4: è©•ä¾¡",         value=True, key="pl_eval")
            do_pca   = st.checkbox("Phase 5: æ¬¡å…ƒå‰Šæ¸›(PCA)",value=True, key="pl_pca")
            do_shap  = st.checkbox("Phase 6: SHAPè§£æ",     value=True, key="pl_shap")

    # â”€â”€ æ—¢å­˜çµæœã®è¡¨ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    existing_pl = st.session_state.get("pipeline_result")
    existing_ml = st.session_state.get("automl_result")

    # ã‚¿ãƒ–è¡¨ç¤º (çµæœãŒã‚ã‚‹å ´åˆ)
    if existing_pl is not None:
        _show_pipeline_result(existing_pl)
        st.markdown("---")
        col_re1, col_re2 = st.columns(2)
        with col_re1:
            if st.button("ğŸ”„ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å†å®Ÿè¡Œ", use_container_width=True, key="rerun_pl"):
                st.session_state["pipeline_result"] = None
                st.session_state["automl_result"] = None
                st.rerun()
        with col_re2:
            if existing_ml and st.button("ğŸ¤– AutoMLã®ã¿å†å®Ÿè¡Œ", use_container_width=True, key="rerun_ml"):
                st.session_state["automl_result"] = None
                st.rerun()
        return

    elif existing_ml is not None:
        # æ—§å½¢å¼ (AutoMLã®ã¿) çµæœè¡¨ç¤º
        st.success(f"âœ… å‰å›ã®çµæœ: æœ€è‰¯ãƒ¢ãƒ‡ãƒ« = **{existing_ml.best_model_key}** | "
                   f"ã‚¹ã‚³ã‚¢ = `{existing_ml.best_score:.4f}`")
        _show_leaderboard(existing_ml)
        if st.button("ğŸ”„ å†å®Ÿè¡Œ", use_container_width=True, key="rerun_old"):
            st.session_state["automl_result"] = None
            st.rerun()
        return

    # â”€â”€ å®Ÿè¡Œãƒœã‚¿ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    c1, c2, c3 = st.columns([1, 3, 1])
    with c2:
        run_clicked = st.button(
            "ğŸš€ ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œï¼ˆEDA â†’ AutoML â†’ SHAPï¼‰",
            use_container_width=True,
            key="run_full",
            type="primary",
        )

    if not run_clicked:
        st.markdown("""
<div style="text-align:center; padding:3rem; color:#555;">
  <div style="font-size:3rem;">ğŸ”¬</div>
  <div style="margin-top:1rem; color:#8888aa;">
    ã€Œãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã€ã‚’æŠ¼ã™ã¨ã€EDA â†’ å‰å‡¦ç† â†’ AutoML â†’ è©•ä¾¡ â†’ æ¬¡å…ƒå‰Šæ¸› â†’ SHAP ã‚’è‡ªå‹•ã§å®Ÿè¡Œã—ã¾ã™
  </div>
  <div style="margin-top:0.5rem; font-size:0.85rem; color:#666;">
    å„ãƒ•ã‚§ãƒ¼ã‚ºã¯ä¸Šã®âš™ï¸è¨­å®šã§å€‹åˆ¥ã«ON/OFFã§ãã¾ã™
  </div>
</div>""", unsafe_allow_html=True)
        return

    # â”€â”€ ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _run_full_pipeline(
        df=df,
        target_col=target_col,
        smiles_col=smiles_col,
        numeric_scaler=numeric_scaler,
        task_override=task_override,
        cv_folds=cv_folds,
        max_models=max_models,
        timeout=timeout,
        do_eda=do_eda,
        do_prep=do_prep,
        do_ml=do_ml,
        do_eval=do_eval,
        do_pca=do_pca,
        do_shap=do_shap,
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _run_full_pipeline(
    df: pd.DataFrame,
    target_col: str,
    *,
    smiles_col: str | None,
    numeric_scaler: str,
    task_override: str,
    cv_folds: int,
    max_models: int,
    timeout: int,
    do_eda: bool,
    do_prep: bool,
    do_ml: bool,
    do_eval: bool,
    do_pca: bool,
    do_shap: bool,
) -> None:
    """ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é †ç•ªã«å®Ÿè¡Œã—ã¦session_stateã«ä¿å­˜ã™ã‚‹ã€‚"""
    TOTAL_PHASES = sum([do_eda, do_prep, do_ml, do_eval, do_pca, do_shap])
    result = PipelineResult()
    start_time = time.time()

    progress_bar = st.progress(0.0)
    phase_status = st.empty()
    log_area     = st.empty()
    log_lines: list[str] = []
    phase_done   = 0

    def _log(msg: str) -> None:
        log_lines.append(msg)
        log_area.markdown(
            "<br>".join(
                f'<span style="color:#8888aa;font-size:0.82rem;">{l}</span>'
                for l in log_lines[-6:]
            ),
            unsafe_allow_html=True,
        )

    def _advance(phase_name: str) -> None:
        nonlocal phase_done
        phase_done += 1
        progress_bar.progress(phase_done / max(TOTAL_PHASES, 1))
        phase_status.markdown(f"**â–¶ {phase_name}**")
        _log(f"âœ… {phase_name} å®Œäº†")

    try:
        # â”€â”€ Phase 1: EDA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if do_eda:
            phase_status.markdown("**Phase 1/6 â€” EDA å®Ÿè¡Œä¸­â€¦**")
            result.eda_summary  = summarize_dataframe(df)
            result.col_stats    = compute_column_stats(df)
            result.outlier_results = detect_outliers(df, method="iqr")
            _advance("Phase 1: EDA")

        # â”€â”€ Phase 2: å‰å‡¦ç†ç¢ºèª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if do_prep:
            phase_status.markdown("**Phase 2/6 â€” å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ä¸­â€¦**")
            detector = TypeDetector()
            dr = detector.detect(df)
            st.session_state["detection_result"] = dr
            st.session_state["step_preprocess_done"] = True
            _advance("Phase 2: å‰å‡¦ç†")

        # â”€â”€ Phase 3: AutoML â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if do_ml:
            phase_status.markdown("**Phase 3/6 â€” AutoML å®Ÿè¡Œä¸­ï¼ˆã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ï¼‰â€¦**")
            automl_log: list[str] = []

            def _cb(step: int, total: int, msg: str) -> None:
                progress_bar.progress(
                    (phase_done / max(TOTAL_PHASES, 1))
                    + (step / total) / max(TOTAL_PHASES, 1)
                )
                _log(f"  [{step}/{total}] {msg}")

            cfg = PreprocessConfig(
                numeric_scaler=numeric_scaler,
                exclude_smiles=True,
                exclude_constant=True,
            )
            engine = AutoMLEngine(
                task=task_override,
                cv_folds=cv_folds,
                max_models=max_models,
                timeout_seconds=timeout,
                progress_callback=_cb,
            )
            automl_res = engine.run(
                df, target_col=target_col, smiles_col=smiles_col,
                preprocess_config=cfg,
            )
            result.automl_result = automl_res
            result.task = automl_res.task if hasattr(automl_res, "task") else task_override
            st.session_state["automl_result"] = automl_res
            if automl_res.warnings:
                result.warnings.extend(automl_res.warnings)
            _advance("Phase 3: AutoML")

        # â”€â”€ Phase 4: è©•ä¾¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if do_eval and result.automl_result is not None:
            phase_status.markdown("**Phase 4/6 â€” ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ä¸­â€¦**")
            try:
                ar = result.automl_result
                # best_pipeline ã¯ AutoMLEngine.run() ã§æ—¢ã« fitæ¸ˆã¿
                bp: Pipeline = ar.best_pipeline
                X = df.drop(columns=[target_col])
                y = df[target_col].values

                y_pred = bp.predict(X)
                task_str = result.task if result.task in ("regression", "classification") else "regression"
                if task_str == "regression":
                    result.model_score = evaluate_regression(y, y_pred,
                                                             model_key=ar.best_model_key,
                                                             cv_mean=ar.best_score)
                else:
                    y_prob = bp.predict_proba(X) if hasattr(bp, "predict_proba") else None
                    result.model_score = evaluate_classification(y, y_pred, y_prob=y_prob,
                                                                 model_key=ar.best_model_key,
                                                                 cv_mean=ar.best_score)
            except Exception as e:
                result.warnings.append(f"è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                _log(f"âš ï¸ è©•ä¾¡ã‚¹ã‚­ãƒƒãƒ—: {e}")
            _advance("Phase 4: è©•ä¾¡")

        # â”€â”€ Phase 5: PCA æ¬¡å…ƒå‰Šæ¸› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if do_pca:
            phase_status.markdown("**Phase 5/6 â€” PCA æ¬¡å…ƒå‰Šæ¸›ä¸­â€¦**")
            try:
                # run_pca ãŒå†…éƒ¨ã§æ•°å€¤åˆ—é¸æŠ + target_colé™¤å¤–ã™ã‚‹
                X_num_df = df.dropna(subset=df.select_dtypes(include="number").columns)
                if X_num_df.select_dtypes(include="number").shape[1] >= 3:  # targetå«ã‚€æ–¹å‘ã§ >= 3
                    emb_df, evr = run_pca(
                        X_num_df, n_components=2, target_col=target_col
                    )
                    result.pca_df  = emb_df
                    result.pca_evr = evr
            except Exception as e:
                result.warnings.append(f"PCAã‚¨ãƒ©ãƒ¼: {e}")
                _log(f"âš ï¸ PCAã‚¹ã‚­ãƒƒãƒ—: {e}")
            _advance("Phase 5: æ¬¡å…ƒå‰Šæ¸›")

        # â”€â”€ Phase 6: SHAP è§£æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if do_shap and result.automl_result is not None:
            phase_status.markdown("**Phase 6/6 â€” SHAP ç‰¹å¾´é‡é‡è¦åº¦è¨ˆç®—ä¸­â€¦**")
            try:
                ar = result.automl_result
                bp: Pipeline = ar.best_pipeline
                # Pipelineã®æœ€çµ‚ã‚¹ãƒ†ãƒƒãƒ—(model)ã‹ã‚‰é‡è¦åº¦ã‚’å–å¾—
                final_estimator = bp[-1] if hasattr(bp, '__getitem__') else bp

                # å¤‰æ›å¾Œã®ç‰¹å¾´é‡åã‚’å–å¾—
                try:
                    preprocessor_step = bp[:-1]  # modelä»¥å¤–
                    X_raw = df.drop(columns=[target_col])
                    X_transformed = preprocessor_step.transform(X_raw)
                    try:
                        feat_names = bp[:-1].get_feature_names_out().tolist()
                    except Exception:
                        feat_names = [f"feature_{i}" for i in range(X_transformed.shape[1])]
                except Exception:
                    feat_names = df.drop(columns=[target_col]).select_dtypes(
                        include="number"
                    ).columns.tolist()

                if hasattr(final_estimator, "feature_importances_"):
                    imps = final_estimator.feature_importances_
                    names = feat_names[:len(imps)]
                    result.shap_importances = dict(
                        sorted(zip(names, imps), key=lambda x: x[1], reverse=True)
                    )
                elif hasattr(final_estimator, "coef_"):
                    coefs = np.abs(final_estimator.coef_.ravel())
                    names = feat_names[:len(coefs)]
                    result.shap_importances = dict(
                        sorted(zip(names, coefs), key=lambda x: x[1], reverse=True)
                    )
                else:
                    # SHAP KernelExplainerï¼ˆä½é€Ÿãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                    import shap
                    X_s = df.drop(columns=[target_col]).select_dtypes(include="number").fillna(0)
                    explainer = shap.KernelExplainer(
                        bp.predict, shap.sample(X_s, min(50, len(X_s)))
                    )
                    shap_vals = explainer.shap_values(X_s.head(50))
                    mean_abs = np.abs(shap_vals).mean(axis=0)
                    result.shap_importances = dict(
                        sorted(zip(X_s.columns.tolist(), mean_abs),
                               key=lambda x: x[1], reverse=True)
                    )
            except Exception as e:
                result.warnings.append(f"SHAPè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                _log(f"âš ï¸ SHAPã‚¹ã‚­ãƒƒãƒ—: {e}")
            _advance("Phase 6: SHAP")

    except Exception as e:
        progress_bar.empty()
        phase_status.empty()
        st.error(f"âŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
            st.code(traceback.format_exc())
        return

    result.elapsed = time.time() - start_time
    st.session_state["pipeline_result"] = result
    st.session_state["step_eda_done"] = do_eda
    st.session_state["step_preprocess_done"] = do_prep

    progress_bar.progress(1.0)
    phase_status.empty()
    log_area.empty()
    st.balloons()
    st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# çµæœè¡¨ç¤º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _show_pipeline_result(pr: PipelineResult) -> None:
    """PipelineResult ã‚’6ãƒ•ã‚§ãƒ¼ã‚ºã‚¿ãƒ–ã§è¡¨ç¤ºã™ã‚‹ã€‚"""
    ar = pr.automl_result

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    best_info = (
        f"æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: **{ar.best_model_key}** | ã‚¹ã‚³ã‚¢: `{ar.best_score:.4f}`"
        if ar else "AutoML ã¯å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“"
    )
    st.success(f"âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ï¼ ({pr.elapsed:.1f}ç§’) | {best_info}")

    for w in pr.warnings:
        st.warning(f"âš ï¸ {w}")

    # ã‚¿ãƒ–
    tabs = st.tabs(["ğŸ“Š EDA", "âš™ï¸ å‰å‡¦ç†", "ğŸ¤– AutoML", "ğŸ“ˆ è©•ä¾¡", "ğŸ“ æ¬¡å…ƒå‰Šæ¸›", "ğŸ’¡ SHAP"])

    # â”€â”€ Tab 0: EDA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tabs[0]:
        st.markdown("### ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã‚µãƒãƒªãƒ¼")
        if pr.eda_summary:
            summ = pr.eda_summary
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("è¡Œæ•°", f"{summ.get('n_rows', '-'):,}")
            c2.metric("åˆ—æ•°", summ.get('n_cols', '-'))
            c3.metric("æ¬ æã‚»ãƒ«æ•°", summ.get('n_missing', '-'))
            c4.metric("é‡è¤‡è¡Œæ•°", summ.get('n_duplicates', '-'))

        if pr.col_stats:
            st.markdown("#### åˆ—ã”ã¨ã®çµ±è¨ˆ")
            rows = []
            for cs in pr.col_stats:
                rows.append({
                    "åˆ—å": cs.name,
                    "å‹": cs.dtype,
                    "ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°": cs.n_unique,
                    "æ¬ æç‡": f"{cs.null_rate:.1%}",
                    "å¹³å‡": f"{cs.mean:.3g}" if cs.mean is not None else "-",
                    "æ¨™æº–åå·®": f"{cs.std:.3g}" if cs.std is not None else "-",
                })
            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

        if pr.outlier_results:
            n_out_cols = sum(1 for r in pr.outlier_results if r.n_outliers > 0)
            st.info(f"IQRå¤–ã‚Œå€¤æ¤œå‡º: **{n_out_cols}åˆ—** ã«å¤–ã‚Œå€¤ã‚ã‚Š")
        else:
            st.info("EDA ã¯å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚âš™ï¸ è¨­å®šã§æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚")

    # â”€â”€ Tab 1: å‰å‡¦ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tabs[1]:
        st.markdown("### âš™ï¸ å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
        dr = st.session_state.get("detection_result")
        if dr:
            col_types: dict[str, list[str]] = {}
            for col, info in dr.column_info.items():
                t = info.col_type.value if hasattr(info.col_type, "value") else str(info.col_type)
                col_types.setdefault(t, []).append(col)

            rows = [{"åˆ—å‹": t, "åˆ—æ•°": len(cols), "åˆ—å": ", ".join(cols[:5]) + ("..." if len(cols) > 5 else "")}
                    for t, cols in col_types.items()]
            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
            st.caption("TypeDetector ã«ã‚ˆã£ã¦è‡ªå‹•ã§å„åˆ—ã®å‹ãŒåˆ¤å®šã•ã‚Œã€æœ€é©ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼/ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒé¸å®šã•ã‚Œã¾ã™ã€‚")
        else:
            st.info("å‰å‡¦ç†ã¯å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚âš™ï¸ è¨­å®šã§æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚")

    # â”€â”€ Tab 2: AutoML â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tabs[2]:
        if ar:
            _show_leaderboard(ar)
        else:
            st.info("AutoML ã¯å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚âš™ï¸ è¨­å®šã§æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚")

    # â”€â”€ Tab 3: è©•ä¾¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tabs[3]:
        st.markdown("### ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
        score = pr.model_score
        if score is not None:
            # to_dict() ã¯Noneãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è‡ªå‹•é™¤å¤–ã™ã‚‹
            score_dict = {
                k: v for k, v in score.to_dict().items()
                if k not in ("model_key", "task")
            }
            label_map = {
                "rmse": "RMSE", "mae": "MAE", "r2": "RÂ²",
                "accuracy": "Accuracy", "f1_weighted": "F1 (weighted)",
                "roc_auc": "ROC-AUC", "cv_mean": "CV Mean",
                "cv_std": "CV Std", "train_time": "å­¦ç¿’æ™‚é–“(s)",
            }
            c_cols = st.columns(min(len(score_dict), 4))
            for i, (k, v) in enumerate(score_dict.items()):
                with c_cols[i % 4]:
                    st.metric(label_map.get(k, k.upper()),
                              f"{v:.4f}" if isinstance(v, float) else str(v))
        else:
            st.info("è©•ä¾¡ã¯å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚âš™ï¸ è¨­å®šã§æœ‰åŠ¹åŒ–ã™ã‚‹ã‹ã€å…ˆã«AutoMLã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

    # â”€â”€ Tab 4: æ¬¡å…ƒå‰Šæ¸› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tabs[4]:
        st.markdown("### ğŸ“ PCA æ¬¡å…ƒå‰Šæ¸›")
        if pr.pca_df is not None:
            evr = pr.pca_evr
            if evr is not None and len(evr) >= 2:
                st.caption(f"PC1 å¯„ä¸ç‡: {evr[0]:.1%} | PC2 å¯„ä¸ç‡: {evr[1]:.1%} | ç´¯ç©: {evr.sum():.1%}")

            df_plot = pr.pca_df.copy()
            target_series = st.session_state["df"][st.session_state["target_col"]].values
            df_plot["target"] = target_series[:len(df_plot)]

            fig = go.Figure(go.Scatter(
                x=df_plot["PC1"], y=df_plot["PC2"],
                mode="markers",
                marker=dict(
                    color=df_plot["target"],
                    colorscale="Viridis",
                    showscale=True,
                    size=6,
                    opacity=0.7,
                ),
                text=[f"{st.session_state['target_col']}={v:.3g}" for v in df_plot["target"]],
                hovertemplate="%{text}<extra></extra>",
            ))
            fig.update_layout(
                plot_bgcolor="rgba(0,0,0,0)",
                paper_bgcolor="rgba(0,0,0,0)",
                font=dict(color="#e0e0f0"),
                xaxis=dict(title="PC1", gridcolor="#333"),
                yaxis=dict(title="PC2", gridcolor="#333"),
                height=420,
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æ¬¡å…ƒå‰Šæ¸›ã¯å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚âš™ï¸ è¨­å®šã§æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚")

    # â”€â”€ Tab 5: SHAP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tabs[5]:
        st.markdown("### ğŸ’¡ ç‰¹å¾´é‡é‡è¦åº¦ (SHAP/Feature Importance)")
        if pr.shap_importances:
            top_n = 20
            items = list(pr.shap_importances.items())[:top_n]
            keys = [k for k, _ in reversed(items)]
            vals = [v for _, v in reversed(items)]

            fig = go.Figure(go.Bar(
                x=vals, y=keys,
                orientation="h",
                marker_color=[
                    f"rgba({int(255 * v / max(vals))}, 100, 255, 0.85)" for v in vals
                ],
                text=[f"{v:.4f}" for v in vals],
                textposition="outside",
            ))
            fig.update_layout(
                plot_bgcolor="rgba(0,0,0,0)",
                paper_bgcolor="rgba(0,0,0,0)",
                font=dict(color="#e0e0f0"),
                xaxis=dict(title="é‡è¦åº¦", gridcolor="#333"),
                yaxis=dict(gridcolor="#333"),
                height=max(300, len(keys) * 28),
                margin=dict(l=150, r=60, t=20, b=40),
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("SHAPè§£æã¯å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚âš™ï¸ è¨­å®šã§æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚")

    # â”€â”€ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")
    c1, c2, c3 = st.columns(3)
    with c1:
        if st.button("ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆè©³ç´°ï¼‰", use_container_width=True, key="goto_eval"):
            st.session_state["page"] = "evaluation"
            st.rerun()
    with c2:
        if st.button("ğŸ’¡ SHAP è©³ç´°è§£æ", use_container_width=True, key="goto_shap"):
            st.session_state["page"] = "interpret"
            st.rerun()
    with c3:
        if st.button("ğŸ“ æ¬¡å…ƒå‰Šæ¸›ï¼ˆè©³ç´°ï¼‰", use_container_width=True, key="goto_dimred"):
            st.session_state["page"] = "dim_reduction"
            st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰è¡¨ç¤ºï¼ˆå…±é€šï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _show_leaderboard(result: AutoMLResult) -> None:
    """ãƒ¢ãƒ‡ãƒ«ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¨ã‚¹ã‚³ã‚¢ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    st.markdown("### ğŸ† ãƒ¢ãƒ‡ãƒ«ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰")
    scores  = result.model_scores
    details = result.model_details

    df_lb = pd.DataFrame([
        {
            "ãƒ©ãƒ³ã‚¯": i + 1,
            "ãƒ¢ãƒ‡ãƒ«": k,
            "ã‚¹ã‚³ã‚¢ï¼ˆå¹³å‡ï¼‰": f"{v:.4f}",
            "æ¨™æº–åå·®": f"{details[k]['std']:.4f}" if k in details else "-",
            "å­¦ç¿’æ™‚é–“(s)": f"{details[k]['fit_time']:.2f}" if k in details else "-",
            "æœ€è‰¯": "ğŸ†" if k == result.best_model_key else "",
        }
        for i, (k, v) in enumerate(
            sorted(scores.items(), key=lambda x: x[1], reverse=True)
        )
    ])
    st.dataframe(df_lb, use_container_width=True, hide_index=True)

    st.markdown("### ğŸ“Š ã‚¹ã‚³ã‚¢æ¯”è¼ƒ")
    sorted_items = sorted(scores.items(), key=lambda x: x[1])
    keys = [k for k, _ in sorted_items]
    vals = [v for _, v in sorted_items]
    colors = ["#7b2ff7" if k == result.best_model_key else "#00d4ff" for k in keys]

    fig = go.Figure(go.Bar(
        x=vals, y=keys, orientation="h",
        marker_color=colors,
        text=[f"{v:.4f}" for v in vals], textposition="outside",
    ))
    fig.update_layout(
        plot_bgcolor="rgba(0,0,0,0)", paper_bgcolor="rgba(0,0,0,0)",
        font=dict(color="#e0e0f0"),
        xaxis=dict(gridcolor="#333", title=result.scoring),
        yaxis=dict(gridcolor="#333"),
        height=max(300, len(keys) * 40),
        margin=dict(l=120, r=50, t=30, b=30),
    )
    st.plotly_chart(fig, use_container_width=True)
